{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfsfjoA2Nt36"
      },
      "outputs": [],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 1\n"
      ],
      "metadata": {
        "id": "4p6qvVGZRi8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "# Configuração\n",
        "VETOR_TAMANHO = 50000\n",
        "SEED = 42\n",
        "NUM_PROCURADO = 12345  # Escolha um número presente ou ausente\n",
        "NUM_WORKERS = 4  # Pode ajustar de acordo com seu CPU\n",
        "\n",
        "# Gerar vetor com números aleatórios\n",
        "np.random.seed(SEED)\n",
        "vetor = np.random.randint(0, 20000, VETOR_TAMANHO)  # Número de até 20.000\n",
        "\n",
        "# Serial\n",
        "def busca_serial(vetor, alvo):\n",
        "    for i, v in enumerate(vetor):\n",
        "        if v == alvo:\n",
        "            return i\n",
        "    return None\n",
        "\n",
        "# Paralela\n",
        "def busca_parcial(parte, offset, alvo):\n",
        "    for i, v in enumerate(parte):\n",
        "        if v == alvo:\n",
        "            return offset + i\n",
        "    return None\n",
        "\n",
        "def busca_paralela(vetor, alvo, num_workers=4):\n",
        "    tamanho_pedaco = len(vetor) // num_workers\n",
        "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
        "        futuros = []\n",
        "        for i in range(num_workers):\n",
        "            inicio = i * tamanho_pedaco\n",
        "            fim = (i + 1) * tamanho_pedaco if i != num_workers - 1 else len(vetor)\n",
        "            futuros.append(executor.submit(busca_parcial, vetor[inicio:fim], inicio, alvo))\n",
        "\n",
        "        for futuro in as_completed(futuros):\n",
        "            resultado = futuro.result()\n",
        "            if resultado is not None:\n",
        "                # Cancela os outros se já encontrou\n",
        "                for f in futuros:\n",
        "                    f.cancel()\n",
        "                return resultado\n",
        "    return None\n",
        "\n",
        "# Execução e comparação de tempo\n",
        "if __name__ == \"__main__\":\n",
        "    # Serial\n",
        "    t1 = time.time()\n",
        "    pos_serial = busca_serial(vetor, NUM_PROCURADO)\n",
        "    t2 = time.time()\n",
        "    tempo_serial = t2 - t1\n",
        "\n",
        "    # Paralela\n",
        "    t3 = time.time()\n",
        "    pos_paralela = busca_paralela(vetor, NUM_PROCURADO, NUM_WORKERS)\n",
        "    t4 = time.time()\n",
        "    tempo_paralela = t4 - t3\n",
        "\n",
        "    speedup = tempo_serial / tempo_paralela if tempo_paralela > 0 else float('inf')\n",
        "\n",
        "    print(f\"Serial: posição = {pos_serial}, tempo = {tempo_serial:.4f} s\")\n",
        "    print(f\"Paralela: posição = {pos_paralela}, tempo = {tempo_paralela:.4f} s\")\n",
        "    print(f\"Speedup: {speedup:.2f}x\")\n"
      ],
      "metadata": {
        "id": "L5LoQM57RDpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 2"
      ],
      "metadata": {
        "id": "wYkl5HU8Roa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Tamanho do vetor\n",
        "SIZE = 5000000\n",
        "\n",
        "def create_random_array(size=SIZE):\n",
        "    \"\"\"Cria um vetor de inteiros aleatórios.\"\"\"\n",
        "    return [random.randint(0, 100000) for _ in range(size)]\n",
        "\n",
        "# ---------- IMPLEMENTAÇÃO SERIAL ----------\n",
        "\n",
        "def serial_sort(arr):\n",
        "    \"\"\"Ordenação serial usando o método nativo do Python (TimSort).\"\"\"\n",
        "    return sorted(arr)\n",
        "\n",
        "# ---------- IMPLEMENTAÇÃO PARALELA ----------\n",
        "\n",
        "def merge(left, right):\n",
        "    \"\"\"Mescla dois arrays ordenados.\"\"\"\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] <= right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    result.extend(left[i:])\n",
        "    result.extend(right[j:])\n",
        "    return result\n",
        "\n",
        "def merge_sort_chunk(arr):\n",
        "    \"\"\"Ordena uma parte do array.\"\"\"\n",
        "    return sorted(arr)\n",
        "\n",
        "def parallel_sort(arr, num_processes=None):\n",
        "    \"\"\"Ordenação paralela usando multiprocessamento.\"\"\"\n",
        "    if num_processes is None:\n",
        "        num_processes = multiprocessing.cpu_count()\n",
        "\n",
        "    # Determina o tamanho de cada parte\n",
        "    chunk_size = len(arr) // num_processes\n",
        "\n",
        "    # Divide o array em partes\n",
        "    chunks = [arr[i:i+chunk_size] for i in range(0, len(arr), chunk_size)]\n",
        "\n",
        "    # Ordena cada parte em paralelo\n",
        "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
        "        sorted_chunks = list(executor.map(merge_sort_chunk, chunks))\n",
        "\n",
        "    # Mescla as partes ordenadas\n",
        "    result = sorted_chunks[0]\n",
        "    for chunk in sorted_chunks[1:]:\n",
        "        result = merge(result, chunk)\n",
        "\n",
        "    return result\n",
        "\n",
        "# ---------- IMPLEMENTAÇÃO PARALELA OTIMIZADA ----------\n",
        "\n",
        "# Funções globais para a versão otimizada\n",
        "def sort_partition(args):\n",
        "    \"\"\"Ordena uma partição do array.\"\"\"\n",
        "    arr, idx = args\n",
        "    partition = arr[idx]\n",
        "    return np.sort(partition)\n",
        "\n",
        "def merge_arrays(arrays):\n",
        "    \"\"\"Mescla arrays ordenados.\"\"\"\n",
        "    if len(arrays) == 1:\n",
        "        return arrays[0]\n",
        "    mid = len(arrays) // 2\n",
        "    left = merge_arrays(arrays[:mid])\n",
        "    right = merge_arrays(arrays[mid:])\n",
        "    # Combina e ordena\n",
        "    merged = np.concatenate([left, right])\n",
        "    merged.sort()\n",
        "    return merged\n",
        "\n",
        "def optimized_parallel_sort(arr):\n",
        "    \"\"\"Versão otimizada da ordenação paralela usando numpy e multiprocessamento.\"\"\"\n",
        "    # Converte para array numpy\n",
        "    np_arr = np.array(arr)\n",
        "\n",
        "    # Divide o trabalho entre os cores disponíveis\n",
        "    num_cores = 3\n",
        "    split_indices = np.array_split(np.arange(len(np_arr)), num_cores)\n",
        "\n",
        "    # Prepara os argumentos\n",
        "    args = [(np_arr, idx) for idx in split_indices]\n",
        "\n",
        "    # Ordena as partições em paralelo\n",
        "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
        "        sorted_partitions = list(executor.map(sort_partition, args))\n",
        "\n",
        "    # Retorna o resultado como uma lista Python\n",
        "    return merge_arrays(sorted_partitions).tolist()\n",
        "\n",
        "def run_optimized_benchmark():\n",
        "    \"\"\"Executa os testes com a versão otimizada.\"\"\"\n",
        "    # Cria o mesmo vetor aleatório para ambos os testes\n",
        "    array = create_random_array()\n",
        "    array_copy = array.copy()\n",
        "\n",
        "    # Testa a versão serial\n",
        "    start_time = time.time()\n",
        "    sorted_serial = serial_sort(array)\n",
        "    serial_time = time.time() - start_time\n",
        "    print(f\"Tempo de execução serial: {serial_time:.6f} segundos\")\n",
        "\n",
        "    # Testa a versão paralela otimizada\n",
        "    start_time = time.time()\n",
        "    sorted_parallel = optimized_parallel_sort(array_copy)\n",
        "    parallel_time = time.time() - start_time\n",
        "    print(f\"Tempo de execução paralelo otimizado: {parallel_time:.6f} segundos\")\n",
        "\n",
        "    # Verifica se os resultados são idênticos\n",
        "    is_correct = sorted_serial == sorted_parallel\n",
        "    print(f\"Os resultados são idênticos? {is_correct}\")\n",
        "\n",
        "    # Calcula o speedup\n",
        "    speedup = serial_time / parallel_time\n",
        "    print(f\"Speedup: {speedup:.2f}x\")\n",
        "\n",
        "    # Verifica se o speedup atende ao requisito\n",
        "    if speedup >= 1.7:\n",
        "        print(\"✓ O requisito de speedup de 1.7x foi atingido.\")\n",
        "    else:\n",
        "        print(\"✗ O requisito de speedup de 1.7x NÃO foi atingido.\")\n",
        "\n",
        "    return serial_time, parallel_time, speedup\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"\\n===== BENCHMARK OTIMIZADO =====\")\n",
        "    run_optimized_benchmark()\n",
        "\n"
      ],
      "metadata": {
        "id": "kLH_XkzVRrxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 3"
      ],
      "metadata": {
        "id": "lGjAww3bepzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def matrix_mult_serial(A, B):\n",
        "    \"\"\"Multiplicação de matrizes - versão serial\"\"\"\n",
        "    rows_A = A.shape[0]\n",
        "    cols_A = A.shape[1]\n",
        "    cols_B = B.shape[1]\n",
        "\n",
        "    # Inicializa a matriz resultado com zeros\n",
        "    result = np.zeros((rows_A, cols_B))\n",
        "\n",
        "    for i in range(rows_A):\n",
        "        for j in range(cols_B):\n",
        "            for k in range(cols_A):\n",
        "                result[i][j] += A[i][k] * B[k][j]\n",
        "\n",
        "    return result\n",
        "\n",
        "def multiply_row(args):\n",
        "    \"\"\"Função auxiliar para processamento paralelo de uma linha\"\"\"\n",
        "    row, A, B = args\n",
        "    cols_B = B.shape[1]\n",
        "    cols_A = A.shape[1]\n",
        "    result_row = np.zeros(cols_B)\n",
        "\n",
        "    for j in range(cols_B):\n",
        "        for k in range(cols_A):\n",
        "            result_row[j] += A[row][k] * B[k][j]\n",
        "\n",
        "    return row, result_row\n",
        "\n",
        "def matrix_mult_parallel(A, B):\n",
        "    \"\"\"Multiplicação de matrizes - versão paralela\"\"\"\n",
        "    rows_A = A.shape[0]\n",
        "    result = np.zeros((rows_A, B.shape[1]))\n",
        "\n",
        "    # Criando lista de argumentos para cada linha\n",
        "    args = [(i, A, B) for i in range(rows_A)]\n",
        "\n",
        "    # Usando Pool para processamento paralelo\n",
        "    with Pool(processes=9) as pool:\n",
        "        results = pool.map(multiply_row, args)\n",
        "\n",
        "    # Reorganizando os resultados\n",
        "    for row, row_result in results:\n",
        "        result[row] = row_result\n",
        "\n",
        "    return result\n",
        "\n",
        "def main():\n",
        "    # Criando matrizes de exemplo\n",
        "    print(\"Criando matrizes A (200x400) e B (400x100)...\")\n",
        "    A = np.random.rand(200, 400)\n",
        "    B = np.random.rand(400, 100)\n",
        "\n",
        "    # Multiplicação serial\n",
        "    print(\"\\nExecutando multiplicação serial...\")\n",
        "    start_time = time.time()\n",
        "    result_serial = matrix_mult_serial(A, B)\n",
        "    serial_time = time.time() - start_time\n",
        "    print(f\"Tempo de execução serial: {serial_time:.4f} segundos\")\n",
        "\n",
        "    # Multiplicação paralela\n",
        "    print(\"\\nExecutando multiplicação paralela...\")\n",
        "    start_time = time.time()\n",
        "    result_parallel = matrix_mult_parallel(A, B)\n",
        "    parallel_time = time.time() - start_time\n",
        "    print(f\"Tempo de execução paralelo: {parallel_time:.4f} segundos\")\n",
        "    print(f\"Número de núcleos utilizados: {cpu_count()}\")\n",
        "\n",
        "    # Comparação e cálculo do speedup\n",
        "    print(\"\\nVerificando resultados...\")\n",
        "    assert np.allclose(result_serial, result_parallel), \"Resultados diferentes!\"\n",
        "\n",
        "    speedup = serial_time / parallel_time\n",
        "\n",
        "    print(\"\\nComparação de desempenho:\")\n",
        "    print(f\"Tempo serial: {serial_time:.4f} segundos\")\n",
        "    print(f\"Tempo paralelo: {parallel_time:.4f} segundos\")\n",
        "    print(f\"Speedup: {speedup:.2f}x\")\n",
        "\n",
        "    if speedup >= 1.5:\n",
        "        print(\"\\n✅ Speedup maior ou igual a 1.5x alcançado!\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Speedup menor que 1.5x. Considere:\")\n",
        "        print(\"- Usar matrizes maiores para melhorar a relação computação/comunicação\")\n",
        "        print(\"- Otimizar a implementação paralela\")\n",
        "        print(\"- Verificar se há outros processos consumindo recursos da CPU\")\n",
        "\n",
        "    return result_parallel\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result_matrix = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_TmVbXnes5w",
        "outputId": "771f7421-ff5a-41da-ce11-513d7a1ebbd8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Criando matrizes A (200x400) e B (400x100)...\n",
            "\n",
            "Executando multiplicação serial...\n",
            "Tempo de execução serial: 9.2102 segundos\n",
            "\n",
            "Executando multiplicação paralela...\n",
            "Tempo de execução paralelo: 7.2572 segundos\n",
            "Número de núcleos utilizados: 2\n",
            "\n",
            "Verificando resultados...\n",
            "\n",
            "Comparação de desempenho:\n",
            "Tempo serial: 9.2102 segundos\n",
            "Tempo paralelo: 7.2572 segundos\n",
            "Speedup: 1.27x\n",
            "\n",
            "⚠️ Speedup menor que 1.5x. Considere:\n",
            "- Usar matrizes maiores para melhorar a relação computação/comunicação\n",
            "- Otimizar a implementação paralela\n",
            "- Verificar se há outros processos consumindo recursos da CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 4"
      ],
      "metadata": {
        "id": "MiF3a5KNgq-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import numpy as np\n",
        "\n",
        "def is_prime(n):\n",
        "    if n < 2 or n % 2 == 0 and n != 2:\n",
        "        return False\n",
        "    for i in range(3, int(n**.5)+1, 2):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def serial_primes(B):\n",
        "    primes = []\n",
        "    for num in B:\n",
        "        if is_prime(num):\n",
        "            primes.append(num)\n",
        "    return primes\n",
        "\n",
        "def worker(chunk):\n",
        "    return [num for num in chunk if is_prime(num)]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    NUM_WORKERS = 8\n",
        "    size = 1_000_000  # Aumentando para 100.000 elementos\n",
        "    max_num = 1_000_000\n",
        "\n",
        "    print(f\"Gerando array com {size} números entre 1 e {max_num}...\")\n",
        "    np.random.seed(42)\n",
        "    A = np.random.randint(1, max_num, size=size)\n",
        "    #A = np.genfromtxt('vet_exerc_B.csv', delimiter=',').astype(int)\n",
        "    chunks = np.array_split(A, NUM_WORKERS)\n",
        "\n",
        "    start_time_serial = time.time()\n",
        "    primes_serial = serial_primes(A)\n",
        "    end_time_serial = time.time()\n",
        "\n",
        "    print(f'Numeros primos encontrados:{len(primes_serial)}')\n",
        "\n",
        "    print(f\"Serial execution time: {end_time_serial - start_time_serial:.2f} seconds\")\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as pool:\n",
        "        results = pool.map(worker, chunks)\n",
        "\n",
        "    primes_parallel = [prime for chunk in results for prime in chunk]\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f'Numeros primos do paralelo encontrados: {len(primes_parallel)}')\n",
        "\n",
        "    print(f\"Parallel execution time: {(end_time_serial - start_time_serial)/(end_time-start_time):.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q02C-odUgt_E",
        "outputId": "5a25c4db-a2a4-4f3a-d9e1-73c539d80ec1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando array com 1000000 números entre 1 e 1000000...\n",
            "Numeros primos encontrados:78397\n",
            "Serial execution time: 6.88 seconds\n",
            "Numeros primos do paralelo encontrados: 78397\n",
            "Parallel execution time: 0.82 seconds\n"
          ]
        }
      ]
    }
  ]
}